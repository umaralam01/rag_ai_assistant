{
  "pages": [
    {
      "page": 1,
      "text": "Why Use NumPy?\nPython lists are flexible but slow for numerical computing because they:\nStore elements as pointers instead of a continuous block of memory.\nLack vectorized operations, relying on loops instead.\nHave significant overhead due to dynamic typing.\nNumPy‚Äôs Superpowers:\nFaster than Python lists (C-optimized backend)\nUses less memory (efficient storage)\nSupports vectorized operations (no explicit loops needed)\nHas built-in mathematical functions\nNumPy vs.¬†Python Lists ‚Äì Performance Test\nLet‚Äôs compare Python lists with NumPy arrays using a simple example.\nExample 1: Adding Two Lists vs.¬†NumPy Arrays\n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \nimport numpy as np\nimport time\n# Python list\nsize = 1_000_000\nlist1 = list(range(size))\nlist2 = list(range(size))\nstart = time.time()\nresult = [x + y for x, y in zip(list1, list2)]\nend = time.time()"
    },
    {
      "page": 2,
      "text": "Key Takeaway: NumPy is significantly faster because it performs operations in C,\navoiding Python loops.\nCreating NumPy Arrays\nüîπ NumPy stores data in a contiguous memory block, making access faster than\nlists.üîπ shape  shows the dimensions of an array.\nprint(\"Python list addition time:\", end - start)\n# NumPy array\narr1 = np.array(list1)\narr2 = np.array(list2)\nstart = time.time()\nresult = arr1 + arr2  # Vectorized operation\nend = time.time()\nprint(\"NumPy array addition time:\", end - start)\nimport numpy as np\n# Creating a 1D NumPy array\narr1 = np.array([1, 2, 3, 4, 5])\nprint(arr1)\n# Creating a 2D NumPy array\narr2 = np.array([[1, 2, 3], [4, 5, 6]])\nprint(arr2)\n# Checking type and shape\nprint(\"Type:\", type(arr1))\nprint(\"Shape:\", arr2.shape)"
    },
    {
      "page": 3,
      "text": "Memory Efficiency ‚Äì NumPy vs.¬†Lists\nLet‚Äôs check memory consumption.\nNumPy arrays use significantly less memory compared to Python lists.\nVectorization ‚Äì No More Loops!\nNumPy avoids loops by applying operations to entire arrays at once using SIMD\n(Single Instruction, Multiple Data) and other low-level optimizations. SIMD is a\nCPU-level optimization provided by modern processors.\nExample 2: Squaring Elements\nNumPy is cleaner and faster!\nSummary\nNumPy is faster than Python lists because it is optimized in C.\nimport sys\nlist_data = list(range(1000))\nnumpy_data = np.array(list_data)\nprint(\"Python list size:\", sys.getsizeof(list_data) * len(list_data), \"bytes\")\nprint(\"NumPy array size:\", numpy_data.nbytes, \"bytes\")\n# Python list (loop-based)\nlist_squares = [x ** 2 for x in list1]\n# NumPy (vectorized)\nnumpy_squares = arr1 ** 2\n‚Ä¢ \n‚Ä¢"
    },
    {
      "page": 4,
      "text": "It consumes less memory due to efficient storage.\nIt provides vectorized operations, removing the need for slow loops.\nEssential for data science and machine learning workflows.\nExercises for Practice\nCreate a NumPy array with values from 10 to 100 and print its shape.\nCompare the time taken to multiply two Python lists vs.¬†two NumPy arrays.\nFind the memory size of a NumPy array with 1 million elements.\nCreating NumPy Arrays\nWhy NumPy Arrays?\nNumPy arrays are the core of numerical computing in Python. They are:\nFaster than Python lists (C-optimized)\nMemory-efficient (store data in a contiguous block)\nSupport vectorized operations that support SIMD (no slow Python loops)\nUsed in ML, Data Science, and AI\n1. Creating NumPy Arrays\nFrom Python Lists:\n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \nimport numpy as np\narr1 = np.array([1, 2, 3, 4, 5])\n# 1D array\narr2 = np.array([[1, 2, 3], [4, 5, 6]])\n# 2D array"
    },
    {
      "page": 5,
      "text": "üîπ Unlike lists, all elements must have the same data type.\nCreating Arrays from Scratch:\nKey Takeaway: NumPy offers powerful shortcuts to create arrays without loops!\n2. Checking Array Properties\nüîπ NumPy arrays are strongly typed, meaning all elements share the same data\ntype.\nprint(arr1)\n# [1 2 3 4 5]\nprint(arr2)\n# [[1 2 3]\n#  [4 5 6]]\nnp.zeros((3, 3))\n# 3x3 array of zeros\nnp.ones((2, 4))\n# 2x4 array of ones\nnp.full((2, 2), 7)\n# 2x2 array filled with 7\nnp.eye(4)\n# 4x4 identity matrix\nnp.arange(1, 10, 2) # [1, 3, 5, 7, 9] (like range)\nnp.linspace(0, 1, 5) # [0. 0.25 0.5 0.75 1.] (evenly spaced)\narr = np.array([[10, 20, 30], [40, 50, 60]])\nprint(\"Shape:\", arr.shape)\n# (2, 3) ‚Üí 2 rows, 3 columns\nprint(\"Size:\", arr.size)\n# 6 ‚Üí total elements\nprint(\"Dimensions:\", arr.ndim) # 2 ‚Üí 2D array\nprint(\"Data type:\", arr.dtype) # int64 (or int32 on Windows)"
    },
    {
      "page": 6,
      "text": "3. Changing Data Types\nEfficient memory usage by choosing the right data type.\n4. Reshaping and Flattening Arrays\nIndexing and slicing\nLets now learn about indexing and slicing in Numpy\narr = np.array([1, 2, 3], dtype=np.float32)\n# Explicit type\nprint(arr.dtype)\n# float32\narr_int = arr.astype(np.int32)\n# Convert float to int\nprint(arr_int)\n# [1 2 3]\n‚Ä¢ \narr = np.array([[1, 2, 3], [4, 5, 6]])\nprint(arr.shape)\n# (2, 3)\nreshaped = arr.reshape((3, 2))\n# Change shape\nprint(reshaped)\n# [[1 2]\n#  [3 4]\n#  [5 6]]\nflattened = arr.flatten()\n# Convert 2D ‚Üí 1D\nprint(flattened)\n# [1 2 3 4 5 6]"
    },
    {
      "page": 7,
      "text": "Indexing (Same as Python Lists)\nSlicing (Extracting Parts of an Array)\nSlicing returns a view, not a copy! Changes affect the original\narray.**\nThis might seem counterintuitive since Python lists create copies when sliced. But\nin NumPy, slicing returns a view of the original array. Both the sliced array and the\noriginal array share the same data in memory, so changes in the slice affect the\noriginal array.\nWhy does this happen?\nMemory Efficiency: Avoids unnecessary copies, making operations faster and\nsaving memory.\nPerformance: Enables faster access and manipulation of large datasets without\nduplicating data.\nUse .copy()  if you need an independent copy.\narr = np.array([10, 20, 30, 40])\nprint(arr[0])\n# 10\nprint(arr[-1]) # 40\narr = np.array([10, 20, 30, 40, 50])\nprint(arr[1:4])\n# [20 30 40] (slice from index 1 to 3)\nprint(arr[:3])\n# [10 20 30] (first 3 elements)\nprint(arr[::2])\n# [10 30 50] (every 2nd element)\n‚Ä¢ \n‚Ä¢ \nsliced = arr[1:4]\nsliced[0] = 999\nprint(arr)\n# [10 999 30 40 50]\n‚Ä¢"
    },
    {
      "page": 8,
      "text": "6. Fancy Indexing & Boolean Masking\nFancy Indexing (Select Multiple Elements)\nBoolean Masking (Filter Data)\nThis is a powerful way to filter large datasets efficiently!\nSummary\nNumPy arrays are faster, memory-efficient alternatives to lists.\nYou can create arrays using np.array() , np.zeros() , np.ones() , etc.\nIndexing & slicing allow efficient data manipulation.\nReshaping & flattening change array structures without copying data.\nFancy indexing & boolean masking help filter and access specific data.\nExercises for Practice\nCreate a 3√ó3 array filled with random numbers and print its shape.\nConvert an array of floats [1.1, 2.2, 3.3]  into integers.\nUse fancy indexing to extract even numbers from [1, 2, 3, 4, 5, 6] .\nReshape a 1D array of size 9 into a 3√ó3 matrix.\narr = np.array([10, 20, 30, 40, 50])\nidx = [0, 2, 4]\n# Indices to select\nprint(arr[idx])\n# [10 30 50]\narr = np.array([10, 20, 30, 40, 50])\nmask = arr > 25\n# Condition: values greater than 25\nprint(arr[mask])\n# [30 40 50]\n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢"
    },
    {
      "page": 9,
      "text": "Use boolean masking to filter numbers greater than 50 in an array.\nMultidimensional Indexing and Axis\nNumPy allows you to efficiently work with multidimensional arrays, where\nindexing and axis manipulation play a crucial role. Understanding how indexing\nworks across multiple dimensions is essential for data science and machine\nlearning tasks.\n1. Understanding Axes in NumPy\nEach dimension in a NumPy array is called an axis. Axes are numbered starting\nfrom 0.\nFor example:\n1D array ‚Üí 1 axis (axis 0)\n2D array ‚Üí 2 axes (axis 0 = rows, axis 1 = columns)\n3D array ‚Üí 3 axes (axis 0 = depth, axis 1 = rows, axis 2 = columns)\nExample: Axes in a 2D Array\nOutput:\n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \nimport numpy as np\narr = np.array([[1, 2, 3],\n[4, 5, 6],\n[7, 8, 9]])\nprint(arr)"
    },
    {
      "page": 10,
      "text": "Axis 0 (rows) ‚Üí Operations move down the columns.\nAxis 1 (columns) ‚Üí Operations move across the rows.\nSumming along axes:\nOutput:\n2. Indexing in Multidimensional Arrays\nYou can access elements using row and column indices.\nYou can also use slicing to extract parts of an array:\nOutput:\n[[1 2 3]\n[4 5 6]\n[7 8 9]]\n‚Ä¢ \n‚Ä¢ \nprint(np.sum(arr, axis=0))\n# Sum along rows (down each column)\nprint(np.sum(arr, axis=1))\n# Sum along columns (across each row)\n[12 15 18]\n# Column-wise sum\n[ 6 15 24]\n# Row-wise sum\n# Accessing an element\nprint(arr[1, 2])\n# Row index 1, Column index 2 ‚Üí Output: 6\nprint(arr[0:2, 1:3])\n# Extracts first 2 rows and last 2 columns\n[[2 3]\n[5 6]]"
    },
    {
      "page": 11,
      "text": "3. Indexing in 3D Arrays\nFor 3D arrays, the first index refers to the ‚Äúdepth‚Äù (sheets of data).\nAccessing elements in 3D:\n4. Practical Example: Selecting Data Along Axes\nOutput:\narr3D = np.array([[[1, 2, 3], [4, 5, 6]],\n[[7, 8, 9], [10, 11, 12]]])\n# Output of arr3D.shape is ‚Üí (depth, rows, columns)\nprint(arr3D.shape)\n# Output: (2, 2, 3) \n# First sheet, second row, third column\nprint(arr3D[0, 1, 2])\n# Output: 6\nprint(arr3D[:, 0, :])\n# Get the first row from both sheets\n# Get all rows of the first column\nfirst_col = arr[:, 0]\nprint(first_col)\n# Output: [1 4 7]\n# Get the first row from each \"sheet\" in a 3D array\nfirst_rows = arr3D[:, 0, :]\nprint(first_rows)\n[[ 1\n2\n3]\n[ 7\n8\n9]]"
    },
    {
      "page": 12,
      "text": "5. Changing Data Along an Axis\nOutput:\n6. Summary\nAxis 0 = rows (vertical movement), Axis 1 = columns (horizontal movement)\nIndexing works as arr[row, column]  for 2D arrays and arr[depth, row, \ncolumn]  for 3D arrays\nSlicing allows extracting subarrays\nOperations along axes help efficiently manipulate data without loops\nData Types in NumPy\nLet‚Äôs learn about NumPy‚Äôs data types and explore how they affect memory usage\nand performance in your arrays.\n1. Introduction to NumPy Data Types\nNumPy arrays are homogeneous, meaning that they can only store elements of the\nsame type. This is different from Python lists, which can hold mixed data types.\nNumPy supports various data types (also called dtypes), and understanding them\nis crucial for optimizing memory usage and performance.\n# Replace all elements in column 1 with 0\narr[:, 1] = 0\nprint(arr)\n[[1 0 3]\n[4 0 6]\n[7 0 9]]\n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢"
    },
    {
      "page": 13,
      "text": "Common Data Types in NumPy:\nint32 , int64 : Integer types with different bit sizes.\nfloat32 , float64 : Floating-point types with different precision.\nbool : Boolean data type.\ncomplex64 , complex128 : Complex number types.\nobject : For storing objects (e.g., Python objects, strings).\nYou can check the dtype of a NumPy array using the .dtype  attribute.\n2. Changing Data Types\nYou can cast (convert) the data type of an array using the .astype()  method. This\nis useful when you need to change the type for a specific operation or when you\nwant to reduce memory usage.\nExample: Changing Data Types\nExample: Downcasting to Save Memory\n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \nimport numpy as np\narr = np.array([1, 2, 3, 4, 5])\nprint(arr.dtype)\n# Output: int64 (or int32 depending on the system)\narr = np.array([1.5, 2.7, 3.9])\nprint(arr.dtype)\n# Output: float64\narr_int = arr.astype(np.int32)\n# Converting float to int\nprint(arr_int)\n# Output: [1 2 3]\nprint(arr_int.dtype)\n# Output: int32\narr_large = np.array([1000000, 2000000, 3000000], dtype=np.int64)\narr_small = arr_large.astype(np.int32)\n# Downcasting to a smaller dtype"
    },
    {
      "page": 14,
      "text": "3. Why Data Types Matter in NumPy\nThe choice of data type affects: - Memory Usage: Smaller data types use less\nmemory. - Performance: Operations on smaller data types are faster due to less\ndata being processed. - Precision: Choosing the appropriate data type ensures that\nyou don‚Äôt lose precision (e.g., using float32  instead of float64  if you don‚Äôt\nneed that extra precision).\nExample: Memory Usage\n4. String Data Type in NumPy\nAlthough NumPy arrays typically store numerical data, you can also store strings by\nusing the dtype='str'  or dtype='U'  (Unicode string) format. However, working\nwith strings in NumPy is less efficient than using lists or Python‚Äôs built-in string\ntypes.\nExample: String Array\nprint(arr_small)\n# Output: [1000000 2000000 3000000]\nprint(arr_small.dtype)\n# Output: int32\narr_int64 = np.array([1, 2, 3], dtype=np.int64)\narr_int32 = np.array([1, 2, 3], dtype=np.int32)\nprint(arr_int64.nbytes)\n# Output: 24 bytes (3 elements * 8 bytes each)\nprint(arr_int32.nbytes)\n# Output: 12 bytes (3 elements * 4 bytes each)\narr = np.array(['apple', 'banana', 'cherry'], dtype='U10')\n# Unicode string array\nprint(arr)"
    },
    {
      "page": 15,
      "text": "5. Complex Numbers\nNumPy also supports complex numbers, which consist of a real and imaginary\npart. You can store complex numbers using complex64  or complex128  data types.\nExample: Complex Numbers\n6. Object Data Type\nIf you need to store mixed or complex data types (e.g., Python objects), you can\nuse dtype='object' . However, this type sacrifices performance, so it should only\nbe used when absolutely necessary.\nExample: Object Data Type\n7. Choosing the Right Data Type\nChoosing the correct data type is essential for: - Optimizing memory: Using the\nsmallest data type that fits your data. - Improving performance: Smaller types\ngenerally lead to faster operations. - Ensuring precision: Avoid truncating or losing\nimportant decimal places or values.\nSummary:\nNumPy arrays are homogeneous, meaning all elements must be of the same\ntype.\nUse .astype()  to change data types and optimize memory and\nperformance.\narr = np.array([1 + 2j, 3 + 4j, 5 + 6j], dtype='complex128')\nprint(arr)\narr = np.array([{'a': 1}, [1, 2, 3], 'hello'], dtype=object)\nprint(arr)\n‚Ä¢ \n‚Ä¢"
    },
    {
      "page": 16,
      "text": "The choice of data type affects memory usage, performance, and precision.\nBe mindful of complex numbers and object data types, which can increase\nmemory usage and reduce performance.\nBroadcasting in NumPy\nNow, we‚Äôll explore how to make your code faster with vectorization and \nbroadcasting in NumPy. These techniques are key to boosting performance in\nnumerical operations by avoiding slow loops and memory inefficiency.\n1. Why Loops Are Slow\nIn Python, loops are typically slow because: - Python‚Äôs interpreter: Every iteration\nof the loop requires Python to interpret the loop logic, which is inherently slower\nthan lower-level, compiled code. - High overhead: Each loop iteration in Python\ninvolves additional overhead for function calls, memory access, and index\nmanagement.\nWhile Python loops are convenient, they don‚Äôt take advantage of the optimized\nmemory and computation that libraries like NumPy provide.\nExample: Looping Over Arrays in Python\nThis works, but it‚Äôs not efficient. Each loop iteration is slow, especially with large\ndatasets.\n‚Ä¢ \n‚Ä¢ \nimport numpy as np\narr = np.array([1, 2, 3, 4, 5])\nresult = []\n# Using a loop to square each element (slow)\nfor num in arr:\n    result.append(num ** 2)\nprint(result)\n# Output: [1, 4, 9, 16, 25]"
    },
    {
      "page": 17,
      "text": "2. Vectorization: Fixing the Loop Problem\nVectorization allows you to perform operations on entire arrays at once, instead of\niterating over elements one by one. This is made possible by NumPy‚Äôs optimized\nC-based backend that executes operations in compiled code, which is much faster\nthan Python loops.\nVectorized operations are also more readable and compact, making your code\neasier to maintain.\nExample: Vectorized Operation\nHere, the operation is applied to all elements of the array simultaneously, and it‚Äôs\nmuch faster than looping over the array.\nWhy is it Faster?\nLow-level implementation: NumPy‚Äôs vectorized operations are implemented\nin C (compiled language), which is much faster than Python loops.\nBatch processing: NumPy processes multiple elements in parallel using SIMD\n(Single Instruction, Multiple Data), allowing multiple operations to be done\nsimultaneously.\n3. Broadcasting: Scaling Arrays Without Extra Memory\nBroadcasting is a powerful feature of NumPy that allows you to perform\noperations on arrays of different shapes without creating copies. It ‚Äústretches‚Äù\nsmaller arrays across larger arrays in a memory-efficient way, avoiding the\noverhead of creating multiple copies of data.\nExample: Broadcasting with Scalar\nBroadcasting is often used when you want to perform an operation on an array\nand a scalar value (e.g., add a number to all elements of an array).\narr = np.array([1, 2, 3, 4, 5])\nresult = arr ** 2\n# Vectorized operation\nprint(result)\n# Output: [1 4 9 16 25]\n‚Ä¢ \n‚Ä¢"
    },
    {
      "page": 18,
      "text": "Here, the scalar 10  is ‚Äúbroadcast‚Äù across the entire array, and no extra memory is\nused.\n4. Broadcasting with Arrays of Different Shapes\nBroadcasting becomes more powerful when you apply operations on arrays of \ndifferent shapes. NumPy automatically adjusts the shapes of arrays to make them\ncompatible for element-wise operations, without actually copying the data.\nExample: Broadcasting with Two Arrays\nNumPy automatically aligns the two arrays and performs element-wise addition,\ntreating them as if they have the same shape.\nExample: Broadcasting a 2D Array and a 1D Array\narr = np.array([1, 2, 3, 4, 5])\nresult = arr + 10\n# Broadcasting: 10 is added to all elements\nprint(result)\n# Output: [11 12 13 14 15]\narr1 = np.array([1, 2, 3])\narr2 = np.array([10, 20, 30])\nresult = arr1 + arr2  # Element-wise addition\nprint(result)\n# Output: [11 22 33]\narr1 = np.array([[1, 2, 3], [4, 5, 6]])\narr2 = np.array([1, 2, 3])\nresult = arr1 + arr2  # Broadcasting arr2 across arr1\nprint(result)\n# Output:\n# [[2 4 6]\n#  [5 7 9]]"
    },
    {
      "page": 19,
      "text": "In this case, arr2  is broadcast across the rows of arr1 , adding [1, 2, 3]  to\neach row.\nHow Broadcasting Works\nDimensions must be compatible: The size of the trailing dimensions of the\narrays must be either the same or one of them must be 1.\nStretching arrays: If the shapes are compatible, NumPy stretches the smaller\narray to match the larger one, element-wise, without copying data.\n5. Hands-on: Applying Broadcasting to Real-World Scenarios\nLet‚Äôs apply broadcasting to a real-world scenario: scaling data in machine learning.\nExample: Normalizing Data Using Broadcasting\nImagine you have a dataset where each row represents a sample and each column\nrepresents a feature. You can normalize the data by subtracting the mean of each\ncolumn and dividing by the standard deviation.\n1. \n2. \n# Simulating a dataset (5 samples, 3 features)\ndata = np.array([[10, 20, 30],\n[15, 25, 35],\n[20, 30, 40],\n[25, 35, 45],\n[30, 40, 50]])\n# Calculating mean and standard deviation for each feature (column)\nmean = data.mean(axis=0)\nstd = data.std(axis=0)\n# Normalizing the data using broadcasting\nnormalized_data = (data - mean) / std\nprint(normalized_data)"
    },
    {
      "page": 20,
      "text": "In this case, broadcasting allows you to subtract the mean and divide by the\nstandard deviation for each feature without needing loops or creating copies of the\ndata.\nSummary:\nLoops are slow because Python‚Äôs interpreter adds overhead, making iteration\nless efficient.\nVectorization allows you to apply operations to entire arrays at once, greatly\nimproving performance by utilizing NumPy‚Äôs optimized C backend.\nBroadcasting enables operations between arrays of different shapes by\nautomatically stretching the smaller array to match the shape of the larger\narray, without creating additional copies.\nReal-world use: Broadcasting can be used in data science tasks, such as \nnormalizing datasets, without sacrificing memory or performance.\nBuilt in Mathematical Functions in\nNumPy\nHere are some common NumPy methods that are frequently used for statistical\nand mathematical operations:\nnp.mean()  ‚Äì Compute the mean (average) of an array.\nnp.std()  ‚Äì Compute the standard deviation of an array.\nnp.var()  ‚Äì Compute the variance of an array.\n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n‚Ä¢ \n1. \nnp.mean(arr)\n2. \nnp.std(arr)\n3."
    },
    {
      "page": 21,
      "text": "np.min()  ‚Äì Compute the minimum value of an array.\nnp.max()  ‚Äì Compute the maximum value of an array.\nnp.sum()  ‚Äì Compute the sum of all elements in an array.\nnp.prod()  ‚Äì Compute the product of all elements in an array.\nnp.median()  ‚Äì Compute the median of an array.\nnp.percentile()  ‚Äì Compute the percentile of an array.\nnp.argmin()  ‚Äì Return the index of the minimum value in an array.\nnp.argmax()  ‚Äì Return the index of the maximum value in an array.\nnp.var(arr)\n4. \nnp.min(arr)\n5. \nnp.max(arr)\n6. \nnp.sum(arr)\n7. \nnp.prod(arr)\n8. \nnp.median(arr)\n9. \nnp.percentile(arr, 50)\n# For the 50th percentile (median)\n10. \nnp.argmin(arr)\n11."
    },
    {
      "page": 22,
      "text": "np.corrcoef()  ‚Äì Compute the correlation coefficient matrix of two arrays.\nnp.unique()  ‚Äì Find the unique elements of an array.\nnp.diff()  ‚Äì Compute the n-th differences of an array.\nnp.cumsum()  ‚Äì Compute the cumulative sum of an array.\nnp.linspace()  ‚Äì Create an array with evenly spaced numbers over a\nspecified interval.\nnp.log()  ‚Äì Compute the natural logarithm of an array.\nnp.exp()  ‚Äì Compute the exponential of an array.\nnp.argmax(arr)\n12. \nnp.corrcoef(arr1, arr2)\n13. \nnp.unique(arr)\n14. \nnp.diff(arr)\n15. \nnp.cumsum(arr)\n16. \nnp.linspace(0, 10, 5)\n# 5 numbers from 0 to 10\n17. \nnp.log(arr)\n18. \nnp.exp(arr)"
    },
    {
      "page": 23,
      "text": "These methods are used for performing mathematical and statistical operations\nwith NumPy"
    }
  ]
}